{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeylaMecnunChatbot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erayyildiz/TurkishConversationBot/blob/master/LeylaMecnunChatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6PoyurBM60q1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "caa2a567-a73e-4426-994f-e6b910fe51e4"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch --upgrade "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 31kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x59cc8000 @  0x7fe6743882a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yZVcQ-ZTBO9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mcBA37HZZwS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbbc25e4-c163-4ff2-c944-f67b09ca31c4"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "97ff80e2-35eb-453b-ba44-c5e249e4e447",
        "id": "EZ7ooIgCiu9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pw70uZAypGa2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "create_subtitle_utterences=False\n",
        "if create_subtitle_utterences:\n",
        "    !wget http://opus.nlpl.eu/download.php?f=OpenSubtitles2018%2Fmono%2FOpenSubtitles2018.raw.tr.gz\n",
        "    !gunzip 'download.php?f=OpenSubtitles2018%2Fmono%2FOpenSubtitles2018.raw.tr.gz'\n",
        "    !mv 'download.php?f=OpenSubtitles2018%2Fmono%2FOpenSubtitles2018.raw.tr' subtitles.txt\n",
        "    previous_line = \"\"\n",
        "    with open(\"subtitles.dialogues.txt\", \"w\") as w:\n",
        "        with open(\"subtitles.txt\", \"r\") as f:\n",
        "            for i, line in enumerate(f):\n",
        "                line = line.strip()\n",
        "                if line.startswith(\"-\"):\n",
        "                    line = line.replace(\"- \", \"\")\n",
        "                    line = line.replace(\"-\", \"\")\n",
        "                    if previous_line:\n",
        "                        w.write(\"{}\\t{}\\n\".format(previous_line, line))\n",
        "                    previous_line = line\n",
        "                else:\n",
        "                    previous_line = \"\"\n",
        "    !mkdir \"gdrive/My Drive/chatbot\"\n",
        "    !cp subtitles.dialogues.txt \"gdrive/My Drive/chatbot/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Xyr8sro-zPz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from nltk.tokenize import casual_tokenize\n",
        "\n",
        "EOS = \"<EOS>\"\n",
        "SOS = \"<SOS>\"\n",
        "\n",
        "def to_lower(txt):\n",
        "    txt = txt.replace('İ', 'i')\n",
        "    txt = txt.replace('Ğ', 'ğ')\n",
        "    txt = txt.replace('Ü', 'ü')\n",
        "    txt = txt.replace('Ş', 'ş')\n",
        "    txt = txt.replace('Ç', 'ç')\n",
        "    txt = txt.replace('Ö', 'ö')\n",
        "    return txt.lower()\n",
        "    \n",
        "\n",
        "utterance_regex = re.compile(r\"^.*[a-zA-Z]+.*$\")\n",
        "nondiaolgue_regex = re.compile(r\"\\[[^\\]]+\\]\")\n",
        "nondiaolgue_regex2 = re.compile(r\"<[^>]+>\")\n",
        "number_regex = re.compile(r\"^[0-9]+$\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wp6nOnm-pyCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_samples = 5000000\n",
        "start_from = 0 \n",
        "subtitle_utterances = []\n",
        "with open(\"gdrive/My Drive/chatbot/subtitles.dialogues.txt\", \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i < start_from:\n",
        "            continue\n",
        "        parses = line.split(\"\\t\")\n",
        "        q = to_lower(parses[0])\n",
        "        a = to_lower(parses[1])\n",
        "        q_tokens = [token for token in casual_tokenize(q) if utterance_regex.match(token)]\n",
        "        a_tokens = [token for token in casual_tokenize(a) if utterance_regex.match(token)]\n",
        "        subtitle_utterances.append((q_tokens, a_tokens))\n",
        "        if i >= max_samples + start_from:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ERSZrOvkJPJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09f72947-3207-4b73-8c49-a6433066b2bc"
      },
      "cell_type": "code",
      "source": [
        "len(subtitle_utterances)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "hafh1Z24BVnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(sentence):\n",
        "    return [word2int[word] for word in sentence if word in word2int]\n",
        "\n",
        "\n",
        "def tensorFromSentence(sentence):\n",
        "    indexes = indexesFromSentence(sentence)\n",
        "    indexes.append(word2int[EOS])\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(pair[0])\n",
        "    target_tensor = tensorFromSentence(pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_uGW8pp0BXyM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        \n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        \n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "    \n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jPSdIVFgVpW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "806ad91d-75a4-43c2-c6a4-cbf683c45f52"
      },
      "cell_type": "code",
      "source": [
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "uRc_ncQpBa6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[word2int[SOS]]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    \n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        decoder_input = target_tensor[di] \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "coUheE13Cog5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B6-H2-ijCqjA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, utterances, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(utterances))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        if input_tensor.shape[0] > 1 and target_tensor.shape[0] > 1:\n",
        "            loss = train(input_tensor, target_tensor, encoder,\n",
        "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "            print_loss_total += loss\n",
        "            plot_loss_total += loss\n",
        "\n",
        "            if iter % print_every == 0:\n",
        "                print_loss_avg = print_loss_total / print_every\n",
        "                print_loss_total = 0\n",
        "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                             iter, iter / n_iters * 100, print_loss_avg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7a8Rex57Cvn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=20, beam_size=10):\n",
        "    with torch.no_grad():\n",
        "        if isinstance(sentence, str):\n",
        "            tokens = casual_tokenize(to_lower(sentence))\n",
        "        elif isinstance(sentence, list):\n",
        "            tokens = sentence\n",
        "        else:\n",
        "            raise TypeError(\"Wrong Input Type: {}\".format(type(sentence)))\n",
        "        input_tensor = tensorFromSentence(tokens)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[word2int[SOS]]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == word2int[EOS]:\n",
        "                decoded_words.append(EOS)\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(int2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z8RJyyhMCxWo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, utterances, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(utterances)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJOMjTohJZq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5af54171-1fb3-4d00-a52b-728af3644066"
      },
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import pickle\n",
        "ENCODER_PATH = \"gdrive/My Drive/chatbot/chatbot.encoder.model\"\n",
        "DECODER_PATH = \"gdrive/My Drive/chatbot/chatbot.decoder.model\"\n",
        "WORDS_PATH = \"gdrive/My Drive/chatbot/chatbot.words\"\n",
        "\n",
        "if os.path.isfile(WORDS_PATH):\n",
        "    print(\"Loading word list\")\n",
        "    with open(WORDS_PATH,\"rb\") as f:\n",
        "        words = pickle.load(f)\n",
        "        \n",
        "else:\n",
        "    word_counts_dic = {}\n",
        "    for utterance in subtitle_utterances:\n",
        "        for word in utterance[0]:\n",
        "            if word not in word_counts_dic:\n",
        "                word_counts_dic[word] = 1\n",
        "            else:\n",
        "                word_counts_dic[word] += 1\n",
        "\n",
        "    min_word_count = 25\n",
        "    words = [SOS, EOS]\n",
        "    words += [w for w, c in word_counts_dic.items() if c >= min_word_count]\n",
        "    with open(WORDS_PATH,\"wb\") as f:\n",
        "        pickle.dump(words,f)\n",
        "\n",
        "int2word = list(words)\n",
        "word2int = {c:i for i,c in enumerate(words)}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word list\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bDcz-0u_H2N4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6335cb9-76fa-4fca-94d6-c6f042b9b475"
      },
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "t2OblheyCzn-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(len(words), hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, len(words)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sHASAdgti2_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "902d96b5-3bba-4281-9952-dc7dd142c430"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_model_states(model, path):\n",
        "    \"\"\"Load a previously saved model states.\"\"\"\n",
        "    # original saved file with DataParallel\n",
        "    state_dict = torch.load(path)\n",
        "    model.load_state_dict(state_dict)\n",
        "        \n",
        "if os.path.isfile(ENCODER_PATH):\n",
        "    print(\"Loading Encoder\")\n",
        "    load_model_states(encoder1, ENCODER_PATH)\n",
        "if os.path.isfile(DECODER_PATH):\n",
        "    print(\"Loading Decoder\")\n",
        "    load_model_states(decoder1, DECODER_PATH)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Encoder\n",
            "Loading Decoder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EWGmjlqNG4iq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "leyla_mecnun_utterances = []\n",
        "counter = 0\n",
        "goon = False\n",
        "for filename in os.listdir(\"gdrive/My Drive/Colab Notebooks/leyla ile mecnun data\"):\n",
        "    cur_utterance = \"\"\n",
        "    previous_line = \"\"\n",
        "    with open(\"gdrive/My Drive/Colab Notebooks/leyla ile mecnun data/{}\".format(filename), \"r\", \n",
        "              encoding=\"ISO-8859-9\") as f:\n",
        "        print(\"Reading file: {}\".format(filename))\n",
        "        for line in f:\n",
        "            line = to_lower(line).strip()\n",
        "            if not utterance_regex.match(line) or line.startswith('#') or len(line) == 0:\n",
        "                if len(cur_utterance) > 0 and len(previous_line):\n",
        "                    previous_line_tokens = [token for token in casual_tokenize(previous_line) if utterance_regex.match(token)]\n",
        "                    cur_utterance_tokens = [token for token in casual_tokenize(cur_utterance) if utterance_regex.match(token)]\n",
        "                    leyla_mecnun_utterances.append((previous_line_tokens, cur_utterance_tokens))\n",
        "                    cur_utterance = \"\"\n",
        "                    previous_line = \"\"\n",
        "                goon = False\n",
        "                continue\n",
        "              \n",
        "            if line.startswith('-'):\n",
        "                line = line.replace(\"-\", \"\")\n",
        "                line = nondiaolgue_regex.sub(r\"\", line).strip()\n",
        "                line = nondiaolgue_regex2.sub(r\"\", line).strip()\n",
        "                line = line.replace(\"#\", \"\")\n",
        "                previous_line = cur_utterance.strip()\n",
        "                cur_utterance = line\n",
        "                counter += 1\n",
        "                goon = True\n",
        "            elif goon:\n",
        "              cur_utterance += \" \" + line\n",
        "            \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7U8er86a2okB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random.sample(subtitle_utterances, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-3FgxfsIrT0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    trainIters(encoder1, decoder1, 100000, subtitle_utterances, print_every=10000, learning_rate=0.001)\n",
        "    print(\"Epoch {} is completed.\".format(epoch))\n",
        "    evaluateRandomly(encoder1, decoder1, subtitle_utterances)\n",
        "    torch.save(encoder1.state_dict(), ENCODER_PATH)\n",
        "    torch.save(decoder1.state_dict(), DECODER_PATH)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DRD6gATvV1jA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "c7e10272-0bc4-4e5b-b877-f0dc7206f536"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "    trainIters(encoder1, decoder1, 10000, leyla_mecnun_utterances, print_every=1000, learning_rate=0.001)\n",
        "    print(\"Epoch {} is completed.\".format(epoch))\n",
        "    "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1m 25s (- 12m 49s) (1000 10%) 4.0868\n",
            "2m 50s (- 11m 20s) (2000 20%) 3.9567\n",
            "4m 14s (- 9m 54s) (3000 30%) 3.7827\n",
            "5m 39s (- 8m 28s) (4000 40%) 3.6652\n",
            "7m 3s (- 7m 3s) (5000 50%) 3.7296\n",
            "8m 28s (- 5m 38s) (6000 60%) 3.6377\n",
            "9m 52s (- 4m 13s) (7000 70%) 3.4612\n",
            "11m 14s (- 2m 48s) (8000 80%) 3.4275\n",
            "12m 38s (- 1m 24s) (9000 90%) 3.5146\n",
            "14m 3s (- 0m 0s) (10000 100%) 3.4253\n",
            "Epoch 0 is completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TCzjK-J6FW8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "\n",
        "while True:\n",
        "    input_txt = input()\n",
        "    clear_output()\n",
        "    output_words = evaluate(encoder1, decoder1, input_txt)\n",
        "    output_sentence = ' '.join(output_words[:-1])\n",
        "    print(\" - {}\".format(output_sentence))\n",
        "    time.sleep(2)\n",
        "    clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}